{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "#python -m pip install git+https://github.com/nalexai/hyperlib.git@main\n",
        "from hyperlib.nn.layers.lin_hyp import LinearHyperbolic\n",
        "from hyperlib.nn.optimizers.rsgd import RSGD\n",
        "from hyperlib.manifold.poincare import Poincare\n",
        "\n",
        "from train import make_X_y, encode_y, scale_X, grouped_train_test_split\n",
        "from hyperlib_eval import get_all_pos_in_neg, get_pos_greater_than_quant\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow_addons.optimizers import AdamW\n",
        "\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474944028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"../../../../data/clean/clean_sample.parquet\")\n",
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "(197305, 991)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474965416
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_X_y(df)\n",
        "X_train, X_test, y_train, y_test = grouped_train_test_split(X, y, y, test_size=0.2)\n",
        "X_train_scale, X_test_scale = scale_X(X_train, X_test)\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train_encode = encode_y(y_train)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474970661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256\r\n",
        "\r\n",
        "train_dataset = Dataset.from_tensor_slices((X_train_scale, y_train_encode)).shuffle(100).batch(BATCH_SIZE)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474973253
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperbolic_layer_1 = LinearHyperbolic(978, Poincare(), 1)\r\n",
        "hyperbolic_layer_2 = LinearHyperbolic(512, Poincare(), 1)\r\n",
        "hyperbolic_layer_3 = LinearHyperbolic(128, Poincare(), 1)\r\n",
        "hyperbolic_layer_4 = LinearHyperbolic(64, Poincare(), 1)\r\n",
        "hyperbolic_layer_5 = LinearHyperbolic(32, Poincare(), 1)\r\n",
        "output_layer = LinearHyperbolic(num_classes, Poincare(), 1)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474973422
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model architecture\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    hyperbolic_layer_1,\r\n",
        "    hyperbolic_layer_2,\r\n",
        "    hyperbolic_layer_3,\r\n",
        "    hyperbolic_layer_4,\r\n",
        "    hyperbolic_layer_5,\r\n",
        "    output_layer\r\n",
        "    ])\r\n",
        "\r\n",
        "# Create optimizer\r\n",
        "optimizer = RSGD(learning_rate=0.02)\r\n",
        "\r\n",
        "# Compile the model with the Riemannian optimizer            \r\n",
        "model.compile(\r\n",
        "    optimizer=optimizer,\r\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474973625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\r\n",
        "\r\n",
        "model.fit(train_dataset,\r\n",
        "        batch_size=BATCH_SIZE,\r\n",
        "        epochs=EPOCHS,\r\n",
        "        verbose=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/20\n617/617 [==============================] - 90s 125ms/step - loss: 9.5816 - sparse_categorical_accuracy: 0.0110\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/20\n617/617 [==============================] - 77s 125ms/step - loss: 9.5741 - sparse_categorical_accuracy: 0.0150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/20\n617/617 [==============================] - 77s 125ms/step - loss: 9.5691 - sparse_categorical_accuracy: 0.0160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/20\n137/617 [=====>........................] - ETA: 1:00 - loss: 9.5667 - sparse_categorical_accuracy: 0.0173\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r138/617 [=====>........................] - ETA: 59s - loss: 9.5667 - sparse_categorical_accuracy: 0.0173 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r537/617 [=========================>....] - ETA: 10s - loss: 9.5655 - sparse_categorical_accuracy: 0.0171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r538/617 [=========================>....] - ETA: 9s - loss: 9.5655 - sparse_categorical_accuracy: 0.0171 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r540/617 [=========================>....] - ETA: 9s - loss: 9.5655 - sparse_categorical_accuracy: 0.0171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r541/617 [=========================>....] - ETA: 9s - loss: 9.5655 - sparse_categorical_accuracy: 0.0172"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474901810
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model = Model(inputs=model.get_layer('linear_hyperbolic_1').input, outputs=model.get_layer('linear_hyperbolic_3').output) #get network up to embedding layer\r\n",
        "embedded = embeddings_model.predict(X_test_scale, verbose=1) #can set batch_size if mem probs"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474901911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def take_sample(embedded, labs, n_groups=1000):\r\n",
        "    \"\"\"\r\n",
        "    Take sample from test set without splitting up perturbagens\r\n",
        "    \"\"\"\r\n",
        "    _, embedded_sample, _, labs_sample = grouped_train_test_split(embedded, labs, labs, test_size=n_groups)\r\n",
        "    return embedded_sample, labs_sample"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474901930
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = pd.DataFrame(embedded, y_test)\r\n",
        "embedded_sample, labs_sample = take_sample(embedded, y_test, n_groups=20)\r\n",
        "df_eval_sample = pd.DataFrame(embedded_sample, labs_sample)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474901949
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def vector_distance_batch(vector_1, vectors_all):\r\n",
        "#    \"\"\"\r\n",
        "#    Return poincare distances between one vector and a set of other vectors.\r\n",
        "#    Parameters\r\n",
        "#    ----------\r\n",
        "#    vector_1 : numpy.array\r\n",
        "#        vector from which Poincare distances are to be computed.\r\n",
        "#        expected shape (dim,)\r\n",
        "#    vectors_all : numpy.array\r\n",
        "#        for each row in vectors_all, distance from vector_1 is computed.\r\n",
        "#        expected shape (num_vectors, dim)\r\n",
        "#    Returns\r\n",
        "#    -------\r\n",
        "#    numpy.array\r\n",
        "#        Contains Poincare distance between vector_1 and each row in vectors_all.\r\n",
        "#        shape (num_vectors,)\r\n",
        "#    \"\"\"\r\n",
        "#    euclidean_dists = np.linalg.norm(vector_1 - vectors_all, axis=1)\r\n",
        "#    norm = np.linalg.norm(vector_1)\r\n",
        "#    all_norms = np.linalg.norm(vectors_all, axis=1)\r\n",
        "#    return np.arccosh(\r\n",
        "#        1 + 2 * (\r\n",
        "#            (euclidean_dists ** 2) / ((1 - norm ** 2) * (1 - all_norms ** 2))\r\n",
        "#        )\r\n",
        "#    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474901969
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474901990
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cores = multiprocessing.cpu_count()-1\r\n",
        "num_partitions = num_cores\r\n",
        "df_split = np.array_split(df_eval_sample, num_partitions)\r\n",
        "\r\n",
        "with multiprocessing.get_context('spawn').Pool() as pool: #avoids CUDA_ERROR_NOT_INITIALIZED\r\n",
        "    pos_in_negs = np.concatenate(pool.map(partial(get_all_pos_in_neg, df=df_eval), df_split)) #parallel function must be imported of avoid AttributeError: Can't get attribute 'get_all_pos_in_neg' on <module '__main__' (built-in)>\r\n",
        "    #pool.close()\r\n",
        "    #pool.join()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474902006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperlib_eval import get_pos_greater_than_quant\r\n",
        "\r\n",
        "incriment = 0.05\r\n",
        "quants = np.arange(0, 1+incriment, incriment)\r\n",
        "pos_quant = get_pos_greater_than_quant(quants, pos_in_negs)\r\n",
        "auc = np.trapz(pos_quant, quants)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474902021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\r\n",
        "ax.plot(quants, pos_quant)\r\n",
        "\r\n",
        "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\r\n",
        "auc_lab = f\"AUC {auc:.2f}\"\r\n",
        "ax.text(0.73, 0.1, auc_lab, transform=ax.transAxes, fontsize=14,\r\n",
        "        verticalalignment='bottom', bbox=props)\r\n",
        "\r\n",
        "plt.title(\"Quantile/Recall for test set pertubagens\")\r\n",
        "plt.xlabel(\"Quantile\")\r\n",
        "plt.ylabel(\"Recall\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655474902032
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pt_tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "azureml_py38_pt_tf"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}