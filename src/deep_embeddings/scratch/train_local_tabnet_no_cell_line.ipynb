{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys \r\n",
        "sys.path.append(\"./tabnet/tf_tabnet/\")\r\n",
        "\r\n",
        "import math\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from sklearn.preprocessing import minmax_scale\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.data import Dataset\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import layers, models, optimizers\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\r\n",
        "from tensorflow.keras.models import load_model, save_model\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "from tensorflow_addons.optimizers import AdamW\r\n",
        "\r\n",
        "from model.arcface_loss import ArcFace\r\n",
        "import tabnet_model\r\n",
        "\r\n",
        "from train import make_X_y, encode_y, scale_X, quantile_X, grouped_train_test_split\r\n",
        "from eval import recall_at_k"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=24):\r\n",
        "    np.random.seed(seed)\r\n",
        "    tf.random.set_seed(seed)\r\n",
        "\r\n",
        "seed_everything(24)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"../../../../data/clean/clean_sample.parquet\")\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573261
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_X_y(df)\n",
        "X_train, X_test, y_train, y_test = grouped_train_test_split(X, y, y, test_size=0.2)\n",
        "X_train_scale, X_test_scale = scale_X(X_train, X_test)\n",
        "#X_train_scale, X_test_scale = quantile_X(X_train, X_test)\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train_encode = encode_y(y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573274
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024\r\n",
        "\r\n",
        "train_dataset = Dataset.from_tensor_slices((dict(X_train), y_train_encode))\r\n",
        "label_dataset = Dataset.from_tensor_slices(y_train_encode)\r\n",
        "dataset = Dataset.zip((train_dataset, label_dataset)).shuffle(100).batch(BATCH_SIZE).prefetch(1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573291
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_keras_input_layer(feature_names):\r\n",
        "    \"\"\"returns list of keras.engine.keras_tensor.KerasTensor\"\"\"\r\n",
        "    \r\n",
        "    model_inputs = list()\r\n",
        "    \r\n",
        "    for name in feature_names:\r\n",
        "        dtype = tf.float32\r\n",
        "        shape = (1,) if dtype==tf.float32 else ()\r\n",
        "        model_inputs.append(tf.keras.Input(shape=shape, name=name, dtype=dtype))\r\n",
        "    \r\n",
        "    return model_inputs"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573312
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_features(keras_inputs, feature_names):\r\n",
        "    encoded_features = list()\r\n",
        "\r\n",
        "    for keras_input, feature_name in zip(keras_inputs, feature_names):\r\n",
        "        # no encoding for numerical features\r\n",
        "        encoded_features.append(keras_input)\r\n",
        "    \r\n",
        "    return encoded_features"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573328
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_params = {\r\n",
        "        \"decision_dim\": 16, \r\n",
        "        \"attention_dim\": 16, \r\n",
        "        \"n_steps\": 5, \r\n",
        "        \"n_shared_glus\": 2, \r\n",
        "        \"n_dependent_glus\": 2, \r\n",
        "        \"relaxation_factor\": 1.5, \r\n",
        "        \"epsilon\": 1e-15, \r\n",
        "        \"virtual_batch_size\": None, \r\n",
        "        \"momentum\": 0.98, \r\n",
        "        \"mask_type\": \"entmax\", \r\n",
        "        \"lambda_sparse\": 1e-4, \r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = list(X_train.columns)\r\n",
        "embedding_size = 32\r\n",
        "\r\n",
        "# Keras model using Functional API\r\n",
        "gene_expression = create_keras_input_layer(feature_names)\r\n",
        "\r\n",
        "x = encode_features(gene_expression, feature_names)\r\n",
        "x = tf.keras.layers.Concatenate()(x)\r\n",
        "x = tabnet_model.TabNetEncoder(**tabnet_params)(x)\r\n",
        "x = layers.Dense(embedding_size, name=\"embedding\")(x) \r\n",
        "l2norm_embedding = layers.Lambda(lambda t: K.l2_normalize(t, axis=1))(x) #https://stackoverflow.com/questions/53960965/normalized-output-of-keras-layer\r\n",
        "\r\n",
        "labels = layers.Input(shape=(1,), dtype = np.int32, name=\"labels\") \r\n",
        "x = ArcFace(num_classes, BATCH_SIZE, max_m=0.2)([l2norm_embedding, labels]) \r\n",
        "output = layers.Activation('softmax')(x)\r\n",
        "\r\n",
        "model = Model([gene_expression, labels], output)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573365
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=SparseCategoricalCrossentropy(),\n",
        "                optimizer=AdamW(learning_rate=5e-3, weight_decay=1e-5),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "model.fit(dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573385
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model = Model(gene_expression, model.get_layer('lambda').output)\r\n",
        "\r\n",
        "embed_dataset = {name: tf.convert_to_tensor(value) for name, value in dict(X_test).items()}\r\n",
        "embedded = embeddings_model.predict(embed_dataset, verbose=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573400
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, embedded_sample, _, labs_sample = grouped_train_test_split(embedded, y_test, y_test, test_size=100)\r\n",
        "print(embedded_sample.shape)\r\n",
        "\r\n",
        "recall = recall_at_k(embedded_sample, embedded, y_test)\r\n",
        "quantile = minmax_scale(np.arange(1, embedded.shape[0]), feature_range=(0, 1))\r\n",
        "\r\n",
        "auc = np.trapz(recall, quantile)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auc_lab = f\"AUC {auc:.2f}\"\r\n",
        "\r\n",
        "fig, ax = plt.subplots()\r\n",
        "ax.plot(quantile, recall)\r\n",
        "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\r\n",
        "ax.text(0.73, 0.1, auc_lab, transform=ax.transAxes, fontsize=14,\r\n",
        "        verticalalignment='bottom', bbox=props)\r\n",
        "plt.title(\"Compound Retrieval for Embedded Signatures in Test Set\")\r\n",
        "plt.xlabel(\"Proportion of Results Included\")\r\n",
        "plt.ylabel(\"Proportion of Compound Instances Identified\")\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573444
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#0.0005 lr, 2048 batch, 25 epochs, got loss 7.83 and 0.81 auc\r\n",
        "#max_m 0.15"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1657031573466
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}